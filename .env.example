# DataChat - AI-Powered Data Analysis Platform
# Environment Configuration Template
# Copy this file to .env and fill in your values

# =============================================================================
# Application Settings
# =============================================================================
PROJECT_NAME="DSPy Prompt Engineer"
DEBUG=True
LOG_LEVEL=INFO
API_V1_STR=/api/v1

# =============================================================================
# Database Configuration (PostgreSQL)
# =============================================================================
# For local development:
DATABASE_URL=postgresql+asyncpg://datachat_user:datachat_password@localhost:5432/datachat
DATABASE_URL_SYNC=postgresql://datachat_user:datachat_password@localhost:5432/datachat

# For Docker:
# DATABASE_URL=postgresql+asyncpg://datachat_user:datachat_password@postgres:5432/datachat
# DATABASE_URL_SYNC=postgresql://datachat_user:datachat_password@postgres:5432/datachat

# =============================================================================
# Redis Configuration
# =============================================================================
# For local development:
REDIS_URL=redis://localhost:6379/0

# For Docker:
# REDIS_URL=redis://redis:6379/0

# =============================================================================
# MinIO Object Storage Configuration
# =============================================================================
# For local development:
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET_NAME=dspy-datasets
MINIO_SECURE=False

# For Docker:
# MINIO_ENDPOINT=minio:9000

# =============================================================================
# OpenAI API Configuration (for DSPy)
# =============================================================================
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo-preview

# Alternative models:
# OPENAI_MODEL=gpt-4
# OPENAI_MODEL=gpt-3.5-turbo

# =============================================================================
# JWT Authentication
# =============================================================================
# Generate a secure secret key:
# python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=your-super-secret-jwt-key-change-this-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# =============================================================================
# Celery Task Queue Configuration
# =============================================================================
# For local development:
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# For Docker:
# CELERY_BROKER_URL=redis://redis:6379/0
# CELERY_RESULT_BACKEND=redis://redis:6379/0

# =============================================================================
# DSPy Prompt Engineering Configuration
# =============================================================================
# Maximum number of training examples for DSPy optimization
DSPY_MAX_TRAIN_SIZE=1000

# Maximum number of development/validation examples
DSPY_MAX_DEV_SIZE=200

# Number of optimization rounds for prompt engineering
DSPY_OPTIMIZATION_ROUNDS=10

# =============================================================================
# Application Limits
# =============================================================================
# Maximum file size for dataset uploads (in MB)
MAX_FILE_SIZE_MB=100

# Maximum concurrent Celery tasks
MAX_CONCURRENT_TASKS=5

# =============================================================================
# CORS Configuration (for frontend)
# =============================================================================
# Comma-separated list of allowed origins
# CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# =============================================================================
# Development/Production Notes
# =============================================================================
# 1. For production, set DEBUG=False
# 2. Use strong, unique SECRET_KEY
# 3. Configure proper CORS_ORIGINS for your frontend domain
# 4. Use environment-specific database credentials
# 5. Consider using a more powerful OpenAI model for better results
# 6. Adjust DSPY_MAX_TRAIN_SIZE based on your dataset size and performance needs
